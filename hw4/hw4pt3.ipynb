{
 "metadata": {
  "name": "",
  "signature": "sha256:39a0303bc859ead3ee45c11692b8190f486300fbe772e258edbfeca08602ac9f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Machine Learning at Scale, Part III"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import BIDMat.{CMat,CSMat,DMat,Dict,IDict,Image,FMat,FND,GMat,GIMat,GSMat,HMat,IMat,Mat,SMat,SBMat,SDMat}\n",
      "import BIDMat.MatFunctions._\n",
      "import BIDMat.SciFunctions._\n",
      "import BIDMat.Solvers._\n",
      "import BIDMat.Plotting._\n",
      "import BIDMach.Learner\n",
      "import BIDMach.models.{FM,GLM,KMeans,KMeansw,LDA,LDAgibbs,Model,NMF,SFA}\n",
      "import BIDMach.datasources.{DataSource,MatDS,FilesDS,SFilesDS}\n",
      "import BIDMach.mixins.{CosineSim,Perplexity,Top,L1Regularizer,L2Regularizer}\n",
      "import BIDMach.updaters.{ADAGrad,Batch,BatchNorm,IncMult,IncNorm,Telescoping}\n",
      "import BIDMach.causal.{IPTW}\n",
      "\n",
      "Mat.checkMKL\n",
      "Mat.checkCUDA\n",
      "GPUmem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "KMeans clustering at scale"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Training models with data that fits in memory is very limiting. But minibatch learners can easily work with data directly from disk. They access data sequentially (which avoids seeking and maximizes disk throughput) and converge in very few passes. We'll look again at the MNIST data set, this time the full version with 8 million images (about 10 GB, and 120x larger than the dataset from lab6). The dataset has been partition into groups of 100k images (e.g. using the unix split command, or in a cluster) and saved in compressed lz4 files. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class xopts extends Learner.Options with SFilesDS.Opts with KMeans.Opts with Batch.Opts; \n",
      "val mnopts = new xopts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next come the options for the data source. There are quite a few of these, but they only need to be set once and apart from the minibatch size, dont need to be tuned. \n",
      "\n",
      "The following options specify various useful traits of the data source. Many of these are default values and dont actually need to be set, but its useful to know what they do."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val mdir = \"/data/MNIST8M/parts/\"\n",
      "mnopts.fnames = List(FilesDS.simpleEnum(mdir+\"scats%02d.smat.lz4\", 1, 0),  // File name templates, %02d is replaced by a number\n",
      "                     FilesDS.simpleEnum(mdir+\"part%02d.smat.lz4\", 1, 0));\n",
      "mnopts.nstart = 0;                 // Starting file number\n",
      "mnopts.nend = 70;                  // Ending file number\n",
      "mnopts.order = 0;                  // (0) sample order, 0=linear, 1=random\n",
      "mnopts.lookahead = 2;              // (2) number of prefetch threads\n",
      "mnopts.featType = 1;               // (1) feature type, 0=binary, 1=linear\n",
      "// These are specific to SfilesDS:\n",
      "mnopts.fcounts = icol(10,784);     // how many rows to pull from each input matrix \n",
      "mnopts.eltsPerSample = 300         // how many rows to allocate (non-zeros per sample)\n",
      "mnopts.addConstFeat = true         // add a constant feature (effectively adds a $\\beta_0$ term to $X\\beta$)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next options define the type of GLM model (linear, logistic etc) through the links value.\n",
      "They also specify through the targets matrix, how to extract target values from the input matrix.\n",
      "Finally the mask is a vector that specifies which data values can be used for training: i.e. it should exclude the target values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnopts.autoReset = false            // Dont reset the GPU after the training run, so we can use a GPU model for prediction\n",
      "mnopts.dim = 300                    // Number of kmeans clusters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we'll create a custom datasource. We need a bit of runtime configuration to ensure that the datasource runs reliably. Because it prefetches files with separate threads, we need to make sure that enough threads are available or it will stall. The <code>threadPool(4)</code> call takes care of this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val ds = {\n",
      "  implicit val ec = threadPool(4)   // make sure there are enough threads (more than the lookahead count)\n",
      "  new SFilesDS(mnopts)              // the datasource\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we define the main learner class, which is built up from various \"plug-and-play\" learning modules."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val nn = new Learner(                // make a learner instance\n",
      "    ds,                              // datasource\n",
      "    new KMeans(mnopts),              // the model (a KMeans model)\n",
      "    null,                            // list of mixins or regularizers\n",
      "    new Batch(mnopts),               // the optimization class to use\n",
      "    mnopts)                          // pass the options to the learner as well\n",
      "nn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Tuning Options"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following options are the important ones for tuning. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnopts.batchSize = 50000\n",
      "mnopts.npasses = 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You invoke the learner the same way as before. You can change the options above after each run to optimize performance. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nn.train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets extract the model as a Floating-point matrix. We included the category features for clustering to make sure that each cluster is a subset of images for one digit. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val model=FMat(nn.modelmat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we build a 30 x 10 array of images to view the first 300 cluster centers as images."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val nx = 30\n",
      "val ny = 10\n",
      "val im = zeros(28,28)\n",
      "val allim = zeros(28*nx,28*ny)\n",
      "for (i<-0 until nx) {\n",
      "    for (j<-0 until ny) {\n",
      "        val slice = model(i+nx*j,10->794)\n",
      "        im(?) = slice(?)\n",
      "        allim((28*i)->(28*(i+1)), (28*j)->(28*(j+1))) = im\n",
      "    }\n",
      "}\n",
      "Image.show(allim kron ones(2,2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll predict using the closest cluster (or 1-NN if you like). The classify function below takes a block of data (which includes the labels in rows 0->10), and predicts using the other features. It then stacks the predicted and actual categories in a <code>2*k</code> matrix, where k is the number of samples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val datamodel = model(?, 10->794)\n",
      "val catmodel = model(?, 0->10)\n",
      "val (vcat, icat) = maxi2(catmodel,2)\n",
      "val mdot = (datamodel \u2219\u2192 datamodel)\n",
      "\n",
      "def classify(a:FMat):IMat = {\n",
      "    val cdata = a(0->10, ?);\n",
      "    val (vm, im) = maxi2(cdata);\n",
      "    val ddata = a(10->794, ?);\n",
      "    val dists = -2 *(datamodel * ddata) + (ddata \u2219 ddata) + mdot;\n",
      "    val (vdist, idist) = mini2(dists);\n",
      "    icat(idist) on im\n",
      "}\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The cmatch function takes the actual and predicted categories and constructs a 10x10 **confusion matrix** from them. The confusion matrix element c(i,j) is the count of inputs that were predicted to be in category i, but are actually in category j. Its basically just a call to the accum function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cmatch(crows:IMat):DMat = {\n",
      "    accum(crows.t, 1.0, 10, 10)\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To evaluate, we'll run the classification on the remainder of the data source (files 71 to 80 which we didnt read yet). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnopts.nstart=71\n",
      "mnopts.nend=80\n",
      "ds.reset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This code draws minibatches from the datasource, computes predictions from them, and then adds the corresponding counts to the confusion matrix <code>acc</code>."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "var k = 0\n",
      "val acc = dzeros(10,10)\n",
      "while (ds.hasNext) {\n",
      "    val mats=ds.next\n",
      "    val f=FMat(mats(0))\n",
      "    acc ~ acc + cmatch(classify(f))\n",
      "    k += 1\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once we have the confusion counts, we can normalize the matrix of counts to produce a matrix sacc which is the fraction of samples with actual label j that are classified as i. \n",
      "\n",
      "Its common to show this matrix as a 2D gray-scale or false-color plot with white as 1.00 and black as 0.0. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val sacc = FMat(acc/sum(acc))\n",
      "Image.show((sacc * 250f) \u2297 ones(64,64))\n",
      "sacc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Its useful to isolate the correct classification rate by digit, which is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val dacc = getdiag(sacc).t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can take the mean of the diagonal accuracies to get an overall accuracy for this model. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean(dacc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a significant performance gap between arithmetic on sparse vs. dense data, and we're going to measure that now. First we need to create some source files for a new datasource. Run the code below.\n",
      "\n",
      "You can monitor progress by inspecting the directory <code>/data/MNIST8M/parts</code>. Once its run, you can comment it out so it doesnt get run again."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for (i <- 0 to 80) {\n",
      "    val c = loadSMat(mdir+\"scats%02d.smat.lz4\" format i)\n",
      "    val d = loadSMat(mdir+\"part%02d.smat.lz4\" format i)\n",
      "    saveFMat(mdir+\"alls%02d.fmat.lz4\" format i, full(c) on full(d))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Modify the DataSource for this notebook from a SFilesDS (a sparse files datasource) to a FilesDS (a dense files source) based on the (just one path) alls matrices we just created. You will need to delete the options related to sparse datasources (fcounts, eltsPerSample and addConstFeat). \n",
      " "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally run the experiment again using the dense data source and with a larger number of clusters (3000). You should reduce the batchSize option to 20000 to avoid memory problems.\n",
      "\n",
      "Include the training time output by the call to <code>nn.train</code> but not the evaluation time (the evaluation code above is not using the GPU). Rerun and fill out the table below: Save this notebook ready for submission. \n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th>Datasource type</th>\n",
      "<th>KMeans Clusters</th>\n",
      "<th>Training time</th>\n",
      "<th>Avg. gflops</th>\n",
      "<th>Accuracy</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Sparse</td>\n",
      "<td>300</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>Dense</td>\n",
      "<td>3000</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "</tr>\n",
      "</table>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}